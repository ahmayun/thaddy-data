import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

object grades {
  def main(args: Array[String]): Unit = {
  }
  // find highly-rated vintage movies earlier than 1960, scored >= 4
  def execute(input1: RDD[String], input2: RDD[String]): RDD[String] = {
    //studentID, classID, grads
    input1.filter(rows => {
        val studentID = rows.split(",")(0)
        studentID.substring(0,2).equals("18")
    })
    .map(rows => {
        val classID = rows.split(",")(1)
        val score = rows.split(",")(2).toInt
        (classID, score)
    })
    .reduceByKey((x, y) => 
        if (x > y) x else y
    )
    .map(rows => rows._1 + ":" + rows._2)
  }
}
